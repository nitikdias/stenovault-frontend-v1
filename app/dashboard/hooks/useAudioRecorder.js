"use client";
import { useState, useRef, useEffect } from 'react';
import { useUser } from '@/context/userContext';

const API_KEY = process.env.NEXT_PUBLIC_API_KEY || "";
const API_BASE_URL = process.env.NEXT_PUBLIC_API_BASE_URL || "";
const sampleRate = 48000;
const recordSec = 6;
const stepSec = 3;
const recordLen = sampleRate * recordSec;  // 288000 samples
const stepLen = sampleRate * stepSec;      // 240000 samples

// --- Helper Functions ---
function flatten(buffers) {
  const total = buffers.reduce((sum, b) => sum + b.length, 0);
  const out = new Float32Array(total);
  let offset = 0;
  for (const b of buffers) { 
    out.set(b, offset); 
    offset += b.length; 
  }
  console.log(`üîß [flatten] Flattened ${buffers.length} buffers into ${total} samples`);
  return out;
}

function encodeWAV(samples) {
  const buf = new ArrayBuffer(44 + samples.length * 2);
  const view = new DataView(buf);
  const writeStr = (o, s) => { 
    for (let i = 0; i < s.length; i++) 
      view.setUint8(o + i, s.charCodeAt(i)); 
  };
  writeStr(0, "RIFF"); 
  view.setUint32(4, 36 + samples.length * 2, true);
  writeStr(8, "WAVE"); 
  writeStr(12, "fmt "); 
  view.setUint32(16, 16, true);
  view.setUint16(20, 1, true); 
  view.setUint16(22, 1, true);
  view.setUint32(24, sampleRate, true); 
  view.setUint32(28, sampleRate * 2, true);
  view.setUint16(32, 2, true); 
  view.setUint16(34, 16, true);
  writeStr(36, "data"); 
  view.setUint32(40, samples.length * 2, true);
  let offset = 44;
  for (let i = 0; i < samples.length; i++, offset += 2) {
    const s = Math.max(-1, Math.min(1, samples[i]));
    view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
  }
  return new Blob([view], { type: 'audio/wav' });
}

async function upload(blob, name, userId) {
  if (!userId) {
    console.error("‚ùå [upload] User ID is required. Upload cancelled.");
    return;
  }
  const f = new FormData();
  f.append("audio", blob, name);
  f.append("user_id", userId);

  console.log(`üì§ [upload] Starting upload: ${name}, size=${(blob.size/1024).toFixed(2)}KB`);

  return fetch(`/api/backend/uploadchunk`, {
    headers: { "X-API-Key": API_KEY },
    credentials: "include",
    method: "POST",
    body: f,
  }).then((res) => {
    if (!res.ok) throw new Error("upload failed " + res.status);
    return res.json();
  });
}

export function useAudioRecorder() {
  const { user } = useUser(); 

  const [mics, setMics] = useState([]);
  const [deviceId, setDeviceId] = useState('');
  const [recording, setRecording] = useState(false);
  const [paused, setPaused] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);

  const userIdRef = useRef(user?.id);

  const micStreamRef = useRef(null);
  const audioCtxRef = useRef(null);
  const processorRef = useRef(null);
  const sourceRef = useRef(null);
  const pcmBuffersRef = useRef([]);
  const chunkCounterRef = useRef(1);
  const startTimeRef = useRef(0);
  const timeoutsRef = useRef([]);
  const uploadPromisesRef = useRef([]);
  const timerRef = useRef(null);
  const recordingRef = useRef(false);
  const lastEmittedSampleRef = useRef(0); // Track last emitted sample position

  useEffect(() => {
    userIdRef.current = user?.id;
    console.log(`üë§ [useEffect] User ID updated: ${user?.id}`);
  }, [user]);

  const startTimer = () => {
    timerRef.current = setInterval(() => { 
      setRecordingTime(prev => prev + 1); 
    }, 1000);
    console.log(`‚è±Ô∏è [startTimer] Timer started`);
  };
  
  const stopTimer = () => {
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
      console.log(`‚è±Ô∏è [stopTimer] Timer stopped`);
    }
  };

  function emitChunk(chunkIndex, isFinal = false) {
    const full = flatten(pcmBuffersRef.current);
    const fullLength = full.length;
    
    console.log(`\n${'='.repeat(80)}`);
    console.log(`üì¶ [emitChunk] STARTING CHUNK ${chunkIndex}${isFinal ? ' (FINAL)' : ''}`);
    console.log(`üì¶ [emitChunk] Total buffer length: ${fullLength} samples (${(fullLength/sampleRate).toFixed(2)}s)`);
    console.log(`üì¶ [emitChunk] Last emitted position: ${lastEmittedSampleRef.current} samples`);
    console.log(`üì¶ [emitChunk] recordLen=${recordLen}, stepLen=${stepLen}`);
    
    // Calculate start and end positions
    let startOffset, endOffset;
    
    if (isFinal) {
      // Final chunk: from last emitted position to end of buffer
      startOffset = lastEmittedSampleRef.current;
      endOffset = fullLength;
      console.log(`üì¶ [emitChunk] FINAL chunk calculation:`);
    } else {
      // üîß FIX: Always use lastEmittedSampleRef for continuity
      startOffset = lastEmittedSampleRef.current;
      endOffset = Math.min(startOffset + recordLen, fullLength);
      console.log(`üì¶ [emitChunk] Regular chunk calculation (from lastEmitted):`);
    }
    
    console.log(`üì¶ [emitChunk]   startOffset = ${startOffset} samples (${(startOffset/sampleRate).toFixed(2)}s)`);
    console.log(`üì¶ [emitChunk]   endOffset = ${endOffset} samples (${(endOffset/sampleRate).toFixed(2)}s)`);
    
    // Validate boundaries
    if (startOffset >= fullLength) {
      console.error(`‚ùå [emitChunk] INVALID: startOffset (${startOffset}) >= buffer length (${fullLength})`);
      console.log(`${'='.repeat(80)}\n`);
      return;
    }
    
    const slice = full.slice(startOffset, endOffset);
    const sliceLength = slice.length;
    
    console.log(`üì¶ [emitChunk] Slice extracted: ${sliceLength} samples (${(sliceLength/sampleRate).toFixed(2)}s)`);
    
    // üîß FIX: Reduce minimum threshold to 0.5 seconds
    if (sliceLength < sampleRate * 0.5) {
      console.warn(`‚ö†Ô∏è [emitChunk] Slice too small (${sliceLength} samples, ${(sliceLength/sampleRate).toFixed(2)}s), SKIPPING`);
      console.log(`${'='.repeat(80)}\n`);
      return;
    }
    
    if (sliceLength === 0) {
      console.warn(`‚ö†Ô∏è [emitChunk] Empty slice, SKIPPING`);
      console.log(`${'='.repeat(80)}\n`);
      return;
    }
    
    // üîß FIX: Update last emitted position based on actual slice end
    lastEmittedSampleRef.current = startOffset + sliceLength;
    console.log(`üì¶ [emitChunk] Updated lastEmittedSample to: ${lastEmittedSampleRef.current}`);
    
    const wav = encodeWAV(slice);
    const name = `chunk_${chunkIndex}${isFinal ? '_final' : ''}.wav`;
    
    console.log(`üöÄ [emitChunk] Encoding WAV: ${name}`);
    console.log(`üöÄ [emitChunk]   WAV size: ${(wav.size/1024).toFixed(2)}KB`);
    console.log(`üöÄ [emitChunk]   Samples: ${sliceLength}`);
    console.log(`üöÄ [emitChunk]   Duration: ${(sliceLength/sampleRate).toFixed(2)}s`);
    console.log(`${'='.repeat(80)}\n`);
    
    const p = upload(wav, name, userIdRef.current)
      .then(() => console.log(`‚úÖ [emitChunk] ${name} uploaded successfully`))
      .catch(err => console.error(`‚ùå [emitChunk] ${name} failed:`, err));
    
    uploadPromisesRef.current.push(p);
    p.finally(() => {
      uploadPromisesRef.current = uploadPromisesRef.current.filter(x => x !== p);
    });
  }

  function scheduleChunks() {
    console.log(`\nüé¨ [scheduleChunks] ========== STARTING CHUNK SCHEDULER ==========`);
    console.log(`üé¨ [scheduleChunks] recordSec=${recordSec}, stepSec=${stepSec}`);
    console.log(`üé¨ [scheduleChunks] recordLen=${recordLen}, stepLen=${stepLen}`);
    
    timeoutsRef.current.forEach(t => clearTimeout(t));
    timeoutsRef.current = [];
    
    function scheduleNext(i) {
      if (!recordingRef.current) {
        console.log(`‚èπÔ∏è [scheduleNext] Recording stopped, exiting scheduler at chunk ${i}`);
        return;
      }
      
      const delay = i === 1 ? recordSec * 1000 : stepSec * 1000;
      
      console.log(`\n‚è∞ [scheduleNext] ========== SCHEDULING CHUNK ${i} ==========`);
      console.log(`‚è∞ [scheduleNext] Delay: ${delay/1000}s`);
      console.log(`‚è∞ [scheduleNext] Last emitted sample: ${lastEmittedSampleRef.current}`);
      
      const t = setTimeout(() => {
        console.log(`\nüîî [scheduleNext] ========== TIMEOUT FIRED FOR CHUNK ${i} ==========`);
        
        if (!recordingRef.current) {
          console.log(`‚èπÔ∏è [scheduleNext timeout] Recording stopped, skipping chunk ${i}`);
          return;
        }
        
        const currentBufferLength = flatten(pcmBuffersRef.current).length;
        const lastEmitted = lastEmittedSampleRef.current;
        const availableNewSamples = currentBufferLength - lastEmitted;
        
        console.log(`üîî [scheduleNext] Current buffer length: ${currentBufferLength} samples (${(currentBufferLength/sampleRate).toFixed(2)}s)`);
        console.log(`üîî [scheduleNext] Last emitted: ${lastEmitted} samples`);
        console.log(`üîî [scheduleNext] Available new samples: ${availableNewSamples} (${(availableNewSamples/sampleRate).toFixed(2)}s)`);
        
        // üîß FIX: Check available samples relative to lastEmitted, not absolute position
        if (availableNewSamples >= sampleRate) {
          console.log(`‚úÖ [scheduleNext] Enough audio available, emitting chunk ${i}`);
          emitChunk(i);
          scheduleNext(i + 1);
        } else {
          console.warn(`‚ö†Ô∏è [scheduleNext] Not enough new audio (${(availableNewSamples/sampleRate).toFixed(2)}s < 1s)`);
          console.warn(`‚ö†Ô∏è [scheduleNext] Retrying in 1 second...`);
          
          setTimeout(() => {
            if (recordingRef.current) {
              const retryBufferLength = flatten(pcmBuffersRef.current).length;
              const retryAvailable = retryBufferLength - lastEmittedSampleRef.current;
              console.log(`üîÑ [scheduleNext retry] Available now: ${retryAvailable} samples (${(retryAvailable/sampleRate).toFixed(2)}s)`);
              
              if (retryAvailable >= sampleRate * 0.5) { // At least 0.5s
                emitChunk(i);
              }
              scheduleNext(i + 1);
            }
          }, 1000);
        }
      }, delay);
      
      timeoutsRef.current.push(t);
    }
    
    scheduleNext(1);
    console.log(`‚úÖ [scheduleChunks] Scheduler initialized\n`);
  }

  const startRec = async (resetTimer = true) => {
    console.log(`\nüéôÔ∏è [startRec] ========== STARTING RECORDING ==========`);
    console.log(`üéôÔ∏è [startRec] resetTimer=${resetTimer}`);
    console.log(`üéôÔ∏è [startRec] deviceId=${deviceId}`);
    
    if (micStreamRef.current) {
      console.log(`üéôÔ∏è [startRec] Stopping existing mic stream`);
      micStreamRef.current.getTracks().forEach(track => track.stop());
    }
    
    if (audioCtxRef.current) {
      try {
        await audioCtxRef.current.close();
        console.log(`üéôÔ∏è [startRec] Closed existing AudioContext`);
      } catch (e) {
        console.warn("‚ö†Ô∏è [startRec] AudioContext close() error:", e);
      }
      audioCtxRef.current = null;
    }

    const stream = await navigator.mediaDevices.getUserMedia({ audio: { deviceId } });
    micStreamRef.current = stream;
    console.log(`üéôÔ∏è [startRec] Got microphone stream`);
    
    audioCtxRef.current = new (window.AudioContext || window.webkitAudioContext)();
    console.log(`üéôÔ∏è [startRec] Created AudioContext, sampleRate=${audioCtxRef.current.sampleRate}`);
    
    sourceRef.current = audioCtxRef.current.createMediaStreamSource(stream);
    processorRef.current = audioCtxRef.current.createScriptProcessor(4096, 1, 1);
    console.log(`üéôÔ∏è [startRec] Created ScriptProcessorNode with bufferSize=4096`);
    
    let audioProcessCallCount = 0;
    processorRef.current.onaudioprocess = (e) => {
      const inputData = new Float32Array(e.inputBuffer.getChannelData(0));
      pcmBuffersRef.current.push(inputData);
      audioProcessCallCount++;
      
      if (audioProcessCallCount % 50 === 0) { // Log every 50 calls
        const totalSamples = pcmBuffersRef.current.reduce((sum, b) => sum + b.length, 0);
        console.log(`üé§ [audioprocess] Call #${audioProcessCallCount}, Total samples: ${totalSamples} (${(totalSamples/sampleRate).toFixed(2)}s)`);
      }
    };

    sourceRef.current.connect(processorRef.current);
    processorRef.current.connect(audioCtxRef.current.destination);
    console.log(`üéôÔ∏è [startRec] Audio pipeline connected`);

    if (resetTimer) {
      pcmBuffersRef.current = [];
      chunkCounterRef.current = 1;
      lastEmittedSampleRef.current = 0;
      uploadPromisesRef.current = [];
      startTimeRef.current = Date.now();
      setRecordingTime(0);
      console.log(`üéôÔ∏è [startRec] Reset all buffers and counters`);
    } else {
      startTimeRef.current = Date.now() - recordingTime * 1000;
      console.log(`üéôÔ∏è [startRec] Resuming from ${recordingTime}s`);
    }

    setRecording(true);
    recordingRef.current = true;
    setPaused(false);
    console.log(`‚úÖ [startRec] Recording state: recording=${true}, paused=${false}`);
    console.log(`‚úÖ [startRec] Starting timer and scheduler\n`);
    
    startTimer();
    scheduleChunks();
  };

  const pauseRec = async () => {
    console.log(`\n‚è∏Ô∏è [pauseRec] ========== PAUSING RECORDING ==========`);
    setPaused(true);
    recordingRef.current = false;
    stopTimer();
    
    console.log(`‚è∏Ô∏è [pauseRec] Clearing ${timeoutsRef.current.length} pending timeouts`);
    timeoutsRef.current.forEach(t => clearTimeout(t));
    timeoutsRef.current = [];
    
    if (micStreamRef.current) {
      micStreamRef.current.getTracks().forEach(track => track.stop());
      console.log(`‚è∏Ô∏è [pauseRec] Stopped mic stream`);
    }
    
    if (audioCtxRef.current && audioCtxRef.current.state !== 'closed') {
      try {
        await audioCtxRef.current.close();
        console.log(`‚è∏Ô∏è [pauseRec] Closed AudioContext`);
      } catch (e) {
        console.warn("‚ö†Ô∏è [pauseRec] AudioContext close() error:", e);
      }
      audioCtxRef.current = null;
    }
    
    processorRef.current = null;
    sourceRef.current = null;
    console.log(`‚úÖ [pauseRec] Paused successfully\n`);
  };

  const resumeRec = async () => {
    console.log(`\n‚ñ∂Ô∏è [resumeRec] ========== RESUMING RECORDING ==========\n`);
    setPaused(false);
    await startRec(false);
  };

  const stopRec = async () => {
    console.log(`\nüõë [stopRec] ========== STOPPING RECORDING ==========`);
    console.log(`üõë [stopRec] Current chunk counter: ${chunkCounterRef.current}`);
    console.log(`üõë [stopRec] Last emitted sample: ${lastEmittedSampleRef.current}`);
    
    setRecording(false);
    recordingRef.current = false;
    setPaused(false);
    stopTimer();
    
    console.log(`üõë [stopRec] Clearing ${timeoutsRef.current.length} pending timeouts`);
    timeoutsRef.current.forEach(t => clearTimeout(t));
    timeoutsRef.current = [];
    
    if (micStreamRef.current) {
      micStreamRef.current.getTracks().forEach(track => track.stop());
      console.log(`üõë [stopRec] Stopped mic stream`);
    }
    
    if (processorRef.current) {
      try { processorRef.current.disconnect(); } catch(e){/* ignore */ }
      console.log(`üõë [stopRec] Disconnected processor`);
    }
    
    if (sourceRef.current) {
      try { sourceRef.current.disconnect(); } catch(e){/* ignore */ }
      console.log(`üõë [stopRec] Disconnected source`);
    }

    if (audioCtxRef.current && audioCtxRef.current.state !== 'closed') {
      const full = flatten(pcmBuffersRef.current);
      const totalSamples = full.length;
      
      console.log(`üõë [stopRec] Final buffer analysis:`);
      console.log(`üõë [stopRec]   Total samples: ${totalSamples} (${(totalSamples/sampleRate).toFixed(2)}s)`);
      console.log(`üõë [stopRec]   Last emitted: ${lastEmittedSampleRef.current} (${(lastEmittedSampleRef.current/sampleRate).toFixed(2)}s)`);
      console.log(`üõë [stopRec]   Remaining: ${totalSamples - lastEmittedSampleRef.current} samples (${((totalSamples - lastEmittedSampleRef.current)/sampleRate).toFixed(2)}s)`);
      
      // Emit final chunk if there's remaining audio
      if (totalSamples > lastEmittedSampleRef.current) {
        const remainingSamples = totalSamples - lastEmittedSampleRef.current;
        console.log(`üõë [stopRec] Emitting final chunk with ${remainingSamples} samples`);
        emitChunk(chunkCounterRef.current, true);
      } else {
        console.log(`üõë [stopRec] No remaining audio to emit`);
      }
      
      console.log(`üõë [stopRec] Waiting for ${uploadPromisesRef.current.length} uploads to complete...`);
      await Promise.allSettled(uploadPromisesRef.current);
      console.log(`‚úÖ [stopRec] All uploads completed`);
      
      try {
        await audioCtxRef.current.close();
        console.log(`üõë [stopRec] Closed AudioContext`);
      } catch(e) {
        console.warn("‚ö†Ô∏è [stopRec] AudioContext close() error:", e);
      }
      audioCtxRef.current = null;
    }
    
    console.log(`‚úÖ [stopRec] Recording stopped successfully\n`);
  };

  useEffect(() => {
    console.log(`üé¨ [useEffect] Initializing audio recorder...`);
    navigator.mediaDevices.enumerateDevices().then(devs => {
      const inputs = devs.filter(d => d.kind === 'audioinput');
      console.log(`üé¨ [useEffect] Found ${inputs.length} audio input devices`);
      setMics(inputs);
      if (inputs[0]) {
        setDeviceId(inputs[0].deviceId);
        console.log(`üé¨ [useEffect] Default device: ${inputs[0].label}`);
      }
    });
    
    return () => {
      console.log(`üßπ [cleanup] Cleaning up audio recorder`);
      stopTimer();
      timeoutsRef.current.forEach(t => clearTimeout(t));
      if (micStreamRef.current) {
        micStreamRef.current.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  return {
    mics,
    deviceId,
    setDeviceId,
    recording,
    paused,
    recordingTime,
    startRec,
    stopRec,
    pauseRec,
    resumeRec,
  };
}
